# CODITECT MEMORY-CONTEXT Infrastructure

Production-ready infrastructure for the Hybrid Centralized + Distributed MEMORY-CONTEXT architecture.

## Overview

This infrastructure provides:

- **PostgreSQL 14** - Central database for all MEMORY-CONTEXT data
- **ChromaDB** - Semantic search with sentence transformers
- **Redis** - Distributed caching (for future sync agents)
- **Context API** - FastAPI service for CRUD operations and search

## Quick Start

### Prerequisites

- Docker and Docker Compose
- Python 3.11+
- pip3

### Installation

```bash
# 1. Run automated setup
./setup.sh

# 2. Verify services are running
docker-compose ps

# 3. Run integration tests
cd tests
python3 test-day1.py

# 4. Access services
# PostgreSQL: localhost:5432
# ChromaDB:   localhost:8000
# Redis:      localhost:6379
```

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│ Framework Submodule (Central Storage)                       │
│                                                               │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │  PostgreSQL  │  │  Context API │  │   ChromaDB   │      │
│  │   (5432)     │  │   (8080)     │  │   (8000)     │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
│         ▲                 ▲                  ▲               │
└─────────┼─────────────────┼──────────────────┼───────────────┘
          │                 │                  │
          │     API Calls   │    Embeddings    │
          │                 │                  │
┌─────────▼─────────────────▼──────────────────▼───────────────┐
│ Master + 23 Submodules (Distributed Cache)                   │
│                                                               │
│  ┌──────────────┐  ┌──────────────┐                         │
│  │   SQLite     │  │ Sync Agent   │                         │
│  │ Local Cache  │  │ (15 min)     │                         │
│  └──────────────┘  └──────────────┘                         │
└───────────────────────────────────────────────────────────────┘
```

## Directory Structure

```
infrastructure/
├── docker-compose.yml          # Main orchestration
├── setup.sh                    # Automated setup script
├── .env                        # Environment variables (generated)
│
├── postgres/
│   ├── schema-migration.sql    # PostgreSQL schema
│   └── init.sh                 # Initialization script
│
├── chromadb/
│   └── setup-collections.py    # ChromaDB setup
│
├── migration/
│   ├── migrate-data.py         # Data migration (Day 4)
│   └── validate-migration.py   # Migration validation
│
├── tests/
│   ├── test-day1.py           # Day 1 integration tests
│   ├── test-day2-3.py         # API tests (Day 2-3)
│   ├── test-day4.py           # Migration tests (Day 4)
│   └── test-day5.py           # Deployment tests (Day 5)
│
└── deployment/
    ├── context-api.service     # Systemd service
    ├── Dockerfile              # Context API container
    └── cloudbuild.yaml         # GCP Cloud Build
```

## Services

### PostgreSQL

**Connection:**
```bash
# psql (inside container)
docker exec -it coditect-postgres psql -U coditect_admin -d coditect_memory_context

# psql (local)
psql -h localhost -p 5432 -U coditect_admin -d coditect_memory_context

# List tables
\dt

# Check metadata
SELECT * FROM db_metadata;
```

**Schema:**
- 9 tables (sessions, patterns, checkpoints, tags, etc.)
- 4 views (active sessions, patterns by usage, etc.)
- Full JSONB support with GIN indexes
- Full-text search with pg_trgm
- Automatic updated_at triggers

### ChromaDB

**Connection:**
```bash
# Health check
curl http://localhost:8000/api/v1/heartbeat

# Python client
python3
>>> import chromadb
>>> client = chromadb.HttpClient(host="localhost", port=8000)
>>> client.list_collections()
```

**Collections:**
- `sessions_embeddings` - Session context summaries
- `checkpoints_embeddings` - Checkpoint descriptions
- `patterns_embeddings` - Extracted patterns

**Embedding Model:** sentence-transformers/all-MiniLM-L6-v2 (384 dimensions)

### Redis

**Connection:**
```bash
# redis-cli (inside container)
docker exec -it coditect-redis redis-cli -a changeme_dev_only

# Test connection
PING
# Returns: PONG
```

## Environment Variables

Located in `.env` file (auto-generated by setup.sh):

```bash
# PostgreSQL
POSTGRES_PASSWORD=changeme_dev_only_<random>
POSTGRES_DB=coditect_memory_context
POSTGRES_USER=coditect_admin

# Redis
REDIS_PASSWORD=changeme_dev_only_<random>

# ChromaDB
CHROMA_TELEMETRY=false

# Context API (Day 2-3)
API_KEY=dev_api_key_<random>
```

**IMPORTANT:** Update passwords for production deployments!

## Commands

### Start Services

```bash
docker-compose up -d
```

### Stop Services

```bash
docker-compose down
```

### View Logs

```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f postgres
docker-compose logs -f chromadb
docker-compose logs -f redis
```

### Restart Service

```bash
docker-compose restart postgres
```

### Reset Everything (DESTRUCTIVE)

```bash
# Stop and remove volumes (all data lost!)
docker-compose down -v

# Re-run setup
./setup.sh
```

## Development Workflow

### Day 1: Infrastructure Setup ✅

```bash
# Run automated setup
./setup.sh

# Verify all services
docker-compose ps

# Run integration tests
cd tests && python3 test-day1.py
```

### Day 2-3: Context API Development

```bash
# Install Context API dependencies
cd ../context-api
pip3 install -r requirements.txt

# Run API locally
python3 main.py
# Or: uvicorn main:app --reload --host 0.0.0.0 --port 8080

# Access docs
open http://localhost:8080/docs

# Run API tests
cd tests && pytest
```

### Day 4: Data Migration

```bash
# Run migration script
cd infrastructure/migration
python3 migrate-data.py

# Validate migration
python3 validate-migration.py

# Run migration tests
cd ../tests && python3 test-day4.py
```

### Day 5: Deployment

```bash
# Build Docker image
cd ../context-api
docker build -t coditect-context-api:latest .

# Deploy as systemd service
sudo cp ../infrastructure/deployment/context-api.service /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl start context-api
sudo systemctl status context-api

# Or deploy to Cloud Run
gcloud builds submit --config cloudbuild.yaml
```

## Troubleshooting

### PostgreSQL won't start

```bash
# Check logs
docker-compose logs postgres

# Common issues:
# 1. Port 5432 already in use
sudo lsof -i :5432  # Find process using port
# Kill local PostgreSQL if running

# 2. Permission issues
docker-compose down -v
./setup.sh  # Re-run setup
```

### ChromaDB won't start

```bash
# Check logs
docker-compose logs chromadb

# Common issues:
# 1. Port 8000 already in use
sudo lsof -i :8000

# 2. Volume permissions
docker-compose down -v
./setup.sh
```

### Schema migration failed

```bash
# Check if init.sh ran
docker-compose logs postgres | grep "initialization complete"

# Manual schema migration
docker exec -it coditect-postgres psql -U coditect_admin -d coditect_memory_context -f /docker-entrypoint-initdb.d/schema-migration.sql
```

### Integration tests fail

```bash
# 1. Ensure services are running
docker-compose ps

# 2. Check service health
curl http://localhost:8000/api/v1/heartbeat  # ChromaDB
docker exec coditect-postgres pg_isready  # PostgreSQL
docker exec coditect-redis redis-cli ping  # Redis

# 3. Check credentials in .env
cat .env

# 4. Run tests with verbose output
cd tests
python3 test-day1.py -v
```

## Performance Tuning

### PostgreSQL

Edit `docker-compose.yml` and add to postgres service:

```yaml
command:
  - "postgres"
  - "-c"
  - "shared_buffers=256MB"
  - "-c"
  - "effective_cache_size=1GB"
  - "-c"
  - "maintenance_work_mem=64MB"
```

### ChromaDB

Increase memory allocation:

```yaml
chromadb:
  deploy:
    resources:
      limits:
        memory: 2G
      reservations:
        memory: 1G
```

### Redis

Add persistence configuration:

```yaml
redis:
  command: redis-server --save 60 1 --loglevel warning
  volumes:
    - redis_data:/data
```

## Monitoring

### Health Checks

```bash
# PostgreSQL
docker exec coditect-postgres pg_isready

# ChromaDB
curl http://localhost:8000/api/v1/heartbeat

# Redis
docker exec coditect-redis redis-cli ping

# Context API (when running)
curl http://localhost:8080/health
```

### Metrics

**PostgreSQL:**
```sql
-- Connection count
SELECT COUNT(*) FROM pg_stat_activity;

-- Database size
SELECT pg_size_pretty(pg_database_size('coditect_memory_context'));

-- Table sizes
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

**ChromaDB:**
```python
import chromadb
client = chromadb.HttpClient(host="localhost", port=8000)

# Collection counts
for collection in client.list_collections():
    print(f"{collection.name}: {collection.count()} documents")
```

## Production Deployment

### Google Cloud Platform

1. **Provision Cloud SQL (PostgreSQL)**
   ```bash
   gcloud sql instances create coditect-postgres \
       --database-version=POSTGRES_14 \
       --tier=db-n1-standard-1 \
       --region=us-central1
   ```

2. **Deploy ChromaDB to Compute Engine**
   ```bash
   # Create instance
   gcloud compute instances create coditect-chromadb \
       --machine-type=n1-standard-2 \
       --image-family=ubuntu-2204-lts \
       --image-project=ubuntu-os-cloud

   # Install Docker and run ChromaDB
   gcloud compute ssh coditect-chromadb -- \
       "sudo apt-get update && \
        sudo apt-get install -y docker.io && \
        sudo docker run -d -p 8000:8000 chromadb/chroma"
   ```

3. **Deploy Context API to Cloud Run**
   ```bash
   gcloud builds submit --config cloudbuild.yaml
   gcloud run deploy context-api \
       --image gcr.io/PROJECT_ID/context-api:latest \
       --platform managed \
       --region us-central1
   ```

## Security

### Secrets Management

**Production checklist:**
- [ ] Update all passwords in `.env`
- [ ] Use Google Cloud Secret Manager for credentials
- [ ] Enable SSL/TLS for PostgreSQL connections
- [ ] Restrict network access (firewall rules)
- [ ] Enable audit logging
- [ ] Implement API key authentication
- [ ] Set up HTTPS for Context API

### Backup Strategy

**PostgreSQL:**
```bash
# Daily backups
docker exec coditect-postgres pg_dump -U coditect_admin coditect_memory_context > backup_$(date +%Y%m%d).sql

# Automated backups (cron)
0 2 * * * /path/to/backup-script.sh
```

**ChromaDB:**
```bash
# Backup ChromaDB data directory
docker run --rm -v chromadb_data:/data -v $(pwd):/backup alpine tar czf /backup/chromadb_backup_$(date +%Y%m%d).tar.gz /data
```

## Support

**Documentation:**
- Architecture: `docs/MEMORY-CONTEXT-ARCHITECTURE-ANALYSIS.md`
- Implementation: `docs/MEMORY-CONTEXT-WEEK1-IMPLEMENTATION.md`
- API Reference: `docs/MEMORY-CONTEXT-API-REFERENCE.md` (to be created)

**Issues:**
- Infrastructure issues: Check Docker Compose logs
- Schema issues: Review PostgreSQL logs
- Migration issues: See migration/ directory
- API issues: Check Context API logs (Day 2-3)

---

**Last Updated:** 2025-11-17
**Version:** 1.0 (Week 1 Implementation)
**Status:** Day 1 Complete - Infrastructure Ready
