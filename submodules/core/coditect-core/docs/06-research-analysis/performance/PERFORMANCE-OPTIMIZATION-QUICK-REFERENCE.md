# TOON Integration - Performance Optimization Quick Reference Card

**Version:** 1.0
**Date:** 2025-11-17
**Audience:** Engineering Team

---

## üî¥ Critical Bottlenecks (MUST FIX Week 1)

### 1. Pre-commit Hook: 3-6 seconds ‚Üí 900ms

```bash
# BEFORE (Sequential - SLOW)
for toon_file in *.toon; do
    python3 toon_to_markdown.py "$toon_file"
done
# Result: 3 seconds for 10 files ‚ùå

# AFTER (Parallel - FAST)
printf '%s\n' *.toon | xargs -n 1 -P 4 -I {} python3 toon_to_markdown.py {}
# Result: 900ms for 10 files ‚úÖ (3.3x faster)
```

**Impact:** Developer experience blocker ‚Üí Prevents adoption
**Effort:** 4 hours
**Priority:** üî¥ CRITICAL

---

### 2. Token Counting: Accuracy + Speed

```python
# BEFORE (Inaccurate)
tokens = len(text) // 4  # ¬±20% error

# AFTER (Accurate + Cached)
import tiktoken
from functools import lru_cache

encoding = tiktoken.encoding_for_model("gpt-4")

@lru_cache(maxsize=1000)
def count_tokens(text: str) -> int:
    return len(encoding.encode(text))

# Cache hit: <1 ¬µs (100,000x faster)
# Cache miss: 100 ¬µs (50x slower than approximation, but accurate)
# Average (70% hit): 30 ¬µs (3.3x improvement)
```

**Impact:** ROI validation + 3-5x faster with cache
**Effort:** 6 hours (tiktoken + caching)
**Priority:** üî¥ CRITICAL

---

### 3. N+1 Database Queries: 110ms ‚Üí 15ms

```python
# BEFORE (N+1 pattern - SLOW)
checkpoints = db.query(Checkpoint).limit(10)  # Query 1
for checkpoint in checkpoints:
    submodules = db.query(Submodule).filter(
        Submodule.checkpoint_id == checkpoint.id
    )  # Query 2-11
# Result: 11 queries, 110ms ‚ùå

# AFTER (Eager loading - FAST)
checkpoints = db.query(Checkpoint) \
    .options(selectinload(Checkpoint.submodules)) \
    .limit(10)  # Single query
# Result: 1 query, 15ms ‚úÖ (7.3x faster)
```

**Impact:** 10x faster checkpoint loads
**Effort:** 8 hours
**Priority:** üî¥ CRITICAL (Week 2)

---

### 4. Database Indexes: 5-10x Query Speedup

```sql
-- Add these indexes immediately (zero code changes)
CREATE INDEX idx_checkpoints_created ON checkpoints(created_at DESC);
CREATE INDEX idx_checkpoints_toon_fts ON checkpoints USING gin(to_tsvector('english', toon_data));
CREATE INDEX idx_submodule_status_project ON submodule_status(project_id);
CREATE INDEX idx_submodule_status_updated ON submodule_status(updated_at DESC);
CREATE INDEX idx_sessions_tenant ON sessions(tenant_id, created_at DESC);
```

**Impact:** 5-10x faster queries
**Effort:** 2 hours
**Priority:** üî¥ CRITICAL (Week 1)

---

## üü° High-Value Optimizations (Week 2-3)

### 5. Redis Caching: 70-90% Hit Rate

```python
import redis.asyncio as redis

class TOONCache:
    def __init__(self):
        self.redis = redis.from_url("redis://localhost:6379")

    async def get_or_convert(self, toon_content: str) -> str:
        cache_key = f"toon:md:{hash(toon_content)}"

        # Try cache first
        cached = await self.redis.get(cache_key)
        if cached:
            return cached.decode()  # Cache hit: 1-2ms

        # Cache miss - convert
        markdown = toon_to_markdown(toon_content)  # 2ms

        # Store with 1-hour TTL
        await self.redis.setex(cache_key, 3600, markdown)

        return markdown
```

**Impact:** 70-90% hit rate ‚Üí 3-5x faster
**Effort:** 8 hours
**Priority:** üü° HIGH (Week 2)

---

### 6. Async Converter Execution: 4-5x Throughput

```python
import asyncio
from concurrent.futures import ProcessPoolExecutor

executor = ProcessPoolExecutor(max_workers=4)

# BEFORE (Blocking)
def convert_to_toon(checkpoint: dict) -> str:
    return encode_to_toon(checkpoint)  # 20ms blocking ‚ùå

# AFTER (Non-blocking)
async def convert_to_toon_async(checkpoint: dict) -> str:
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        executor,
        encode_to_toon,
        checkpoint
    )  # 20ms non-blocking ‚úÖ
```

**Impact:** 4-5x API throughput
**Effort:** 12 hours
**Priority:** üü° HIGH (Week 2)

---

### 7. Background TOON Generation: 10x User Latency

```python
from fastapi import BackgroundTasks

@app.post("/api/v1/checkpoints")
async def create_checkpoint(
    checkpoint: CheckpointCreate,
    background_tasks: BackgroundTasks
):
    # 1. Save checkpoint immediately (no TOON yet)
    db_checkpoint = Checkpoint(id=uuid4(), data=checkpoint.dict())
    await db.add(db_checkpoint)
    await db.commit()  # User doesn't wait for TOON generation

    # 2. Generate TOON in background
    background_tasks.add_task(generate_toon, db_checkpoint.id)

    return {"id": db_checkpoint.id, "status": "processing"}

# User latency: 10-20ms ‚úÖ (was 100ms ‚ùå)
```

**Impact:** 10x user-facing latency reduction
**Effort:** 6 hours
**Priority:** üü° HIGH (Week 2)

---

## üìä Performance Targets

### Phase 1 Targets (Week 1)

| Metric | Baseline | Target | Status |
|--------|----------|--------|--------|
| Pre-commit hook (10 files) | 3 sec | <1 sec | ‚è≥ Week 1 |
| Token counting (with cache) | N/A | <10 ms | ‚è≥ Week 1 |
| Database query p95 | N/A | <100 ms | ‚è≥ Week 1 |
| Checkpoint creation | 500 ms | <400 ms | ‚è≥ Week 1 |

### Phase 2 Targets (Week 2-3)

| Metric | Baseline | Target | Status |
|--------|----------|--------|--------|
| Cache hit rate | 0% | >70% | ‚è≥ Week 2 |
| API throughput | 10 req/s | >50 req/s | ‚è≥ Week 2 |
| API response p95 | N/A | <500 ms | ‚è≥ Week 2 |
| N+1 query elimination | 110 ms | <20 ms | ‚è≥ Week 2 |

### Scalability Targets

| Load | CPU | Memory | Status |
|------|-----|--------|--------|
| 1x (baseline) | <1% | <100 MB | ‚úÖ Current |
| 10x | <10% | <500 MB | ‚úÖ Achievable |
| 100x (optimized) | <30% | <2 GB | ‚è≥ Phase 2 needed |

---

## üéØ Week 1 Action Plan (18 hours)

### Day 1 (6 hours)
- [ ] Add database indexes (2 hours)
- [ ] Implement tiktoken token counting (2 hours)
- [ ] Add LRU cache for token counts (2 hours)
- [ ] Test: Token counting accuracy <1% error

### Day 2 (6 hours)
- [ ] Implement BaseConverter abstraction (4 hours)
- [ ] Add telemetry for token savings (2 hours)
- [ ] Test: Converter inheritance working

### Day 3 (6 hours)
- [ ] Parallelize pre-commit hook (4 hours)
- [ ] Add pre-commit hook validation (2 hours)
- [ ] Test: 10 files convert in <1 second

### End of Week 1
- [ ] Performance dashboard deployed
- [ ] Baseline metrics collected
- [ ] Phase 1 targets validated
- [ ] Week 2 plan approved

---

## üö® Common Pitfalls to Avoid

### 1. Cache Invalidation

‚ùå **Wrong:**
```python
# Stale cache after update
cache[checkpoint_id] = markdown
# Later: checkpoint updated, cache not invalidated
```

‚úÖ **Right:**
```python
# Version-based cache keys
cache_key = f"checkpoint:{id}:v{version}"
# Or: Short TTL for frequently updated data
await redis.setex(cache_key, 300, markdown)  # 5-minute TTL
```

---

### 2. Database Connection Pool Exhaustion

‚ùå **Wrong:**
```python
# Default pool too small for high load
pool_size=10, max_overflow=20  # Only 30 total
# At 50 concurrent requests: 20 requests queued ‚ùå
```

‚úÖ **Right:**
```python
# Scale pool for production load
pool_size=20, max_overflow=30  # 50 total
# Monitor utilization, scale as needed
```

---

### 3. Blocking Operations in Async Code

‚ùå **Wrong:**
```python
async def convert(checkpoint):
    # CPU-bound operation blocks event loop
    return encode_to_toon(checkpoint)  # 20ms blocking ‚ùå
```

‚úÖ **Right:**
```python
async def convert(checkpoint):
    # Run CPU-bound in executor
    return await loop.run_in_executor(
        executor, encode_to_toon, checkpoint
    )  # 20ms non-blocking ‚úÖ
```

---

## üìà Monitoring Quick Check

### Essential Metrics to Track

```python
# Request latency histogram
request_latency = Histogram(
    'toon_request_duration_seconds',
    'Request latency',
    ['endpoint', 'status']
)

# Token savings counter
tokens_saved = Counter(
    'toon_tokens_saved_total',
    'Total tokens saved via TOON'
)

# Cache performance
cache_hits = Counter('toon_cache_hits_total')
cache_misses = Counter('toon_cache_misses_total')

# Database query duration
db_query_duration = Histogram(
    'db_query_duration_seconds',
    'DB query duration',
    ['query_type']
)
```

### Alert Thresholds

```
üî¥ CRITICAL (page immediately):
- API p95 latency > 1 second
- Database connection pool > 95%
- Error rate > 5%

üü° WARNING (investigate next day):
- API p95 latency > 500ms
- Cache hit rate < 60%
- Pre-commit hook > 5 seconds

‚ÑπÔ∏è INFO (monitor trends):
- Token savings < projected (weekly)
- CPU utilization > 70%
```

---

## üîß Debugging Performance Issues

### Slow API Response

```bash
# 1. Check database queries
# Add logging to database.py
echo=True  # Log all SQL queries

# 2. Profile endpoint
import cProfile
cProfile.runctx('endpoint()', globals(), locals(), 'profile.stats')

# 3. Check cache hit rate
redis-cli INFO stats | grep hits
```

### High CPU Usage

```bash
# 1. Profile CPU-intensive operations
python -m cProfile -s cumulative main.py

# 2. Check for blocking operations
# Look for synchronous calls in async code

# 3. Scale horizontally
# Deploy additional API instances
```

### Database Slow Queries

```sql
-- Enable slow query log
ALTER DATABASE coditect_memory_context SET log_min_duration_statement = 200;

-- Find slow queries
SELECT query, mean_exec_time, calls
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;

-- Analyze query plan
EXPLAIN ANALYZE
SELECT * FROM checkpoints WHERE ...;
```

---

## üìö Quick Reference Links

**Full Analysis:**
- `/docs/TOON-PERFORMANCE-ANALYSIS-AND-SCALABILITY-ASSESSMENT.md` (technical deep dive)
- `/docs/TOON-PERFORMANCE-METRICS-DASHBOARD.md` (visual metrics)
- `/docs/PERFORMANCE-ANALYSIS-EXECUTIVE-SUMMARY.md` (executive summary)

**Architecture:**
- `/docs/TOON-ARCHITECTURE-REVIEW-EXECUTIVE-SUMMARY.md` (architecture review)
- `/docs/TOON-INTEGRATION-PROJECT-PLAN.md` (8-week plan)
- `/docs/MEMORY-CONTEXT-WEEK1-IMPLEMENTATION.md` (database setup)

**Code Examples:**
- `/scripts/prototype_checkpoint_toon.py` (TOON prototype)
- `/context-api/` (FastAPI implementation)

---

## ‚úÖ Checklist: Performance Optimization Complete

### Week 1 (Phase 1)
- [ ] tiktoken + caching implemented
- [ ] Pre-commit hook parallelized
- [ ] Database indexes added
- [ ] BaseConverter abstraction complete
- [ ] Performance dashboard deployed
- [ ] Baseline metrics collected

### Week 2-3 (Phase 2)
- [ ] Redis caching operational
- [ ] N+1 queries eliminated
- [ ] Async converters implemented
- [ ] Background tasks working
- [ ] Token savings validated
- [ ] Phase 2 targets met

### Week 4+ (Validation)
- [ ] Weekly token savings reports
- [ ] ROI estimates updated
- [ ] Performance SLAs met
- [ ] Scale testing complete (10x load)
- [ ] Documentation updated
- [ ] Training materials created

---

**Document Status:** ‚úÖ QUICK REFERENCE COMPLETE
**Audience:** Engineering team implementing TOON optimizations
**Maintained By:** CODITECT Platform Team
**Last Updated:** 2025-11-17
**Version:** 1.0
