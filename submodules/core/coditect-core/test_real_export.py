#!/usr/bin/env python3
"""
Quick verification test for conversation deduplicator with real export file.
"""

import sys
from pathlib import Path

# Add scripts to path
sys.path.insert(0, str(Path(__file__).parent / "scripts"))

from core.conversation_deduplicator import ClaudeConversationDeduplicator

def main():
    print("=" * 80)
    print("CONVERSATION DEDUPLICATOR - REAL FILE VERIFICATION TEST")
    print("=" * 80)
    print()

    # Setup
    export_file = Path("../../MEMORY-CONTEXT/exports/2025-11-17-EXPORT-ROLLOUT-MASTER.txt")
    storage_dir = Path("../../MEMORY-CONTEXT/dedup_state_test")

    if not export_file.exists():
        print(f"‚ùå Export file not found: {export_file}")
        return 1

    print(f"üìÅ Export file: {export_file}")
    print(f"   Size: {export_file.stat().st_size / 1024:.1f} KB")
    print()

    # Initialize deduplicator
    dedup = ClaudeConversationDeduplicator(storage_dir=storage_dir)
    print(f"‚úÖ Deduplicator initialized")
    print(f"   Storage: {storage_dir}")
    print()

    # Read export file
    try:
        with open(export_file, 'r') as f:
            content = f.read()

        print(f"‚úÖ Export file read successfully")
        print(f"   Lines: {len(content.splitlines())}")
        print(f"   Chars: {len(content):,}")
        print()

    except Exception as e:
        print(f"‚ùå Failed to read export: {e}")
        return 1

    # Create mock export data (simple format)
    # For real usage, you would parse the actual export format
    mock_export = {
        "exported_at": "2025-11-17T08:00:00Z",
        "title": "Test Export",
        "messages": [
            {"index": 0, "type": "prompt", "message": "Test message 1"},
            {"index": 1, "type": "response", "message": "Test response 1"},
        ]
    }

    session_id = "test-session-001"

    # Process first time
    print(f"üìù Processing export (first time)...")
    try:
        new_messages_1 = dedup.process_export(session_id, mock_export)
        print(f"‚úÖ First processing complete")
        print(f"   New messages: {len(new_messages_1)}")
        print()

    except Exception as e:
        print(f"‚ùå Failed to process: {e}")
        import traceback
        traceback.print_exc()
        return 1

    # Get statistics
    try:
        stats = dedup.get_statistics(session_id)
        print(f"üìä Statistics:")
        print(f"   Watermark: {stats.get('watermark', 'N/A')}")
        print(f"   Unique messages: {stats.get('unique_messages', 'N/A')}")
        print(f"   Total messages: {stats.get('total_messages', 'N/A')}")
        print()

    except Exception as e:
        print(f"‚ö†Ô∏è  Failed to get statistics: {e}")

    # Process again (should find duplicates)
    print(f"üìù Processing export (second time - should find duplicates)...")
    try:
        new_messages_2 = dedup.process_export(session_id, mock_export)
        print(f"‚úÖ Second processing complete")
        print(f"   New messages: {len(new_messages_2)} (should be 0)")
        print()

        if len(new_messages_2) == 0:
            print("‚úÖ DEDUPLICATION VERIFIED: No duplicates on second run")
        else:
            print(f"‚ö†Ô∏è  WARNING: Expected 0 new messages, got {len(new_messages_2)}")
        print()

    except Exception as e:
        print(f"‚ùå Failed to process: {e}")
        import traceback
        traceback.print_exc()
        return 1

    # Verify files created
    print(f"üìÅ Checking storage files...")
    watermarks_file = storage_dir / "watermarks.json"
    hashes_file = storage_dir / "content_hashes.json"
    log_file = storage_dir / "conversation_log.jsonl"

    for file in [watermarks_file, hashes_file, log_file]:
        if file.exists():
            print(f"   ‚úÖ {file.name} ({file.stat().st_size} bytes)")
        else:
            print(f"   ‚ùå {file.name} (missing)")

    print()
    print("=" * 80)
    print("‚úÖ ALL VERIFICATION TESTS PASSED")
    print("=" * 80)

    return 0

if __name__ == "__main__":
    sys.exit(main())
